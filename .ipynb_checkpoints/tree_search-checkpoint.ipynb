{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a0d226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sntn/opt/anaconda3/envs/left/lib/python3.10/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "from datasets import load_dataset\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0cba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sntn/opt/anaconda3/envs/left/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "data_set_name = \"code_search_net\"\n",
    "language = \"java\"\n",
    "dataset = load_dataset(data_set_name, language)\n",
    "\n",
    "system_prompt = \"create documentation from the code in the question using the example answers that are given\"\n",
    "#model_name = 'llama3'\n",
    "model_name = 'mistral'\n",
    "\n",
    "#model_name = 'llamca3'\n",
    "#model_name = 'mistral'\n",
    "#model_name = 'codegemma:code'\n",
    "# Set up the LM\n",
    "llm = dspy.OllamaLocal(model_name)\n",
    "#model_name = 'gpt-3.5-turbo-instruct'\n",
    "#turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct', max_tokens=250)\n",
    "\n",
    "#dspy.settings.configure(lm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1562c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make training set \n",
    "kcases = 200\n",
    "training_data=[]\n",
    "for x in range(kcases):\n",
    "    k=random.randrange(454450)\n",
    "    case=dspy.Example(question=dataset['train'][k]['func_code_string'], answer=dataset['train'][k]['func_documentation_string']).with_inputs('question')\n",
    "    training_data.append(case)\n",
    "    \n",
    "#make test set \n",
    "\n",
    "\n",
    "kcases = 10\n",
    "test_data=[]\n",
    "for x in range(kcases):\n",
    "    k=random.randrange(454450)\n",
    "    case=dspy.Example(question=dataset['train'][k]['func_code_string'], answer=dataset['train'][k]['func_documentation_string']).with_inputs('question')\n",
    "    test_data.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d177a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "/Users/sntn/opt/anaconda3/envs/left/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#define a metric and a model \n",
    "def sentenceSimilarity(example, pred,  trace=None):\n",
    "    example_arr = [example]\n",
    "    pred_arr = [pred]\n",
    "    example_embedding = model.encode(example_arr, convert_to_tensor=True)\n",
    "    prediction_embedding = model.encode(pred_arr, convert_to_tensor=True)\n",
    "    return(util.pytorch_cos_sim(example_embedding, prediction_embedding).item())\n",
    "\n",
    "sentence_transformer_name = \"multi-qa-mpnet-base-dot-v1\"\n",
    "#sentence_transformer_name = \"all-MiniLM-L6-v2\"\n",
    "#sentence_transformer_name = \"stsb-roberta-large\"\n",
    "\n",
    "model = SentenceTransformer(sentence_transformer_name)\n",
    "metric_name =\"sentence similarity \" + sentence_transformer_name\n",
    "\n",
    "similarity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed015086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pruning threshold', '0'], ['pruning delay', '100'], ['breadth', '1'], ['max demos', 0], ['sparsity', 0.0], ['model name', 'mistral'], ['metric name', 'sentence similarity multi-qa-mpnet-base-dot-v1'], ['algorithm', 'tree search'], ['training set size', '200'], ['run date ', '2024-06-11 22:01:00.304318']]\n",
      "\u001b[2K\u001b[1GDone in 15:20 at 22:16:20/200 0:09min/perc 0.21it/s | 15:200:09 => 15:20\n",
      "\u001b[2K\u001b[1GDone in 15:20 at 22:16:20 15:20min/perc 0.00it/s | 15:20\n",
      "round 0fitness = 71.38120234012604\n",
      "\u001b[2K\u001b[1GDone in 15:20 at 22:16:20 15:20min/perc 0.00it/s | 15:20\n",
      "[]\n",
      "You are a software document writer. There will be a java function for you to document using the template styles. Reply with the approporate documentation\n"
     ]
    }
   ],
   "source": [
    "import TreeSearch \n",
    "treesearcher=TreeSearch.TreeSearch(model=llm, pruning_threshold=0, pruning_delay=100,max_rounds=1,\n",
    "                                   max_labeled_demos=0, sparsity_demos=0.0, training_set = training_data, breadth = 1,\n",
    "                                  metric_name = metric_name, model_name = model_name,data_set_name=data_set_name)\n",
    "\n",
    "highest_so_far, highest_fitness=treesearcher.compile(sentenceSimilarity,training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63dcbba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TreeSearch.TreeSearch at 0x7fd2e35cfa30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treesearcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"hello\"\n",
    "#turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct', max_tokens=250)\n",
    "turbo = dspy.OllamaLocal(model='llama3')\n",
    "response = turbo.request(prompt)\n",
    "print (response[\"choices\"][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(similarity, labels, cmap = \"YlGnBu\"):\n",
    "  df = pd.DataFrame(similarity)\n",
    "  df.columns = labels\n",
    "  df.index = labels\n",
    "  fig, ax = plt.subplots(figsize=(5,5))\n",
    "  sns.heatmap(df, cmap=cmap)\n",
    "\n",
    "\n",
    "\n",
    "def heatmap(training_data):\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    docs = [nlp(n.answer) for n in training_data]\n",
    "    labels = [training_data.answer[:20] for training_data in training_data]\n",
    "    similarity = []\n",
    "    for i in range(len(docs)):\n",
    "        row = []\n",
    "        for j in range(len(docs)):\n",
    "          row.append(docs[i].similarity(docs[j]))\n",
    "        similarity.append(row)\n",
    "    create_heatmap(similarity,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d047a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(\"question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.prog(question=question)\n",
    "    \n",
    "class Pred(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.Predict(\"question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.prog(question=question)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1090bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TreeSearch\n",
    "kcases = 10\n",
    "training_data=[]\n",
    "for x in range(kcases):\n",
    "    k=random.randrange(454450)\n",
    "    case=dspy.Example(question=dataset['train'][k]['func_code_string'], answer=dataset['train'][k]['func_documentation_string']).with_inputs('question')\n",
    "    training_data.append(case)\n",
    "treesearcher=TreeSearch.TreeSearch(model=turbo, pruning_threshold=0.01, pruning_delay=10,max_rounds=30,\n",
    "                                   max_labeled_demos=8, sparsity_demos=0.5, training_set = training_data, breadth = 10 )\n",
    "treesearcher.test_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba2ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7033d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a spacy embedding model to compare the example's answer to the classifiers prediction\n",
    "def validate_answer(example, pred, trace=None):\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    print (pred)\n",
    "    answer_vec=nlp(example.answer)\n",
    "    pred_vec=nlp(pred.answer)\n",
    "    return (answer_vec.similarity(pred_vec))\n",
    "\n",
    "embeddings=[]\n",
    "\n",
    "\n",
    "\n",
    "def sentenceSimilarity(example, pred,  trace=None):\n",
    "    example_arr = [example.answer]\n",
    "    pred_arr = [pred.answer]\n",
    "    example_embedding = model.encode(example_arr, convert_to_tensor=True)\n",
    "    prediction_embedding = model.encode(pred_arr, convert_to_tensor=True)\n",
    "    return(util.pytorch_cos_sim(example_embedding, prediction_embedding).item())\n",
    "\n",
    "#model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "#model = SentenceTransformer('stsb-roberta-large')\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "\n",
    "exp = dspy.Example(question=\"some question\", answer=\"This is an indentical sentence\")\n",
    "prd = dspy.Example(question=\"another question\", answer=\"This is an indentical sentence\")\n",
    "\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "prd = dspy.Example(question=\"another question\", answer=\"This is a different sentence\")\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "prd = dspy.Example(question=\"another question\", answer=\"zookeepers and elephants dance the night away\")\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "prd = dspy.Example(question=\"another question\", answer=\"This is an indenticl sentence\")\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "prd = dspy.Example(question=\"another question\", answer=\"This is an identical phrase\")\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "\n",
    "\n",
    "similarity = []\n",
    "#for i in range(len(sentences)):\n",
    " #   row = []\n",
    "   # for j in range(len(sentences)):\n",
    "   #   row.append(util.pytorch_cos_sim(embeddings[i], embeddings[j]).item())\n",
    "#similarity.append(row)\n",
    "    \n",
    "#create_heatmap(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad811c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch,BootstrapFewShotWithOptuna,MIPRO, LabeledFewShot\n",
    "from dspy.teleprompt.vanilla import LabeledFewShot\n",
    "#model = SentenceTransformer('stsb-roberta-large')\n",
    "#model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "#trainModel()\n",
    "\n",
    "# Set up the optimizer: we want to \"bootstrap\" (i.e., self-generate) 4-shot examples of our CoT program.\n",
    "#config = dict(max_bootstrapped_demos=8, max_labeled_demos=8)\n",
    "config = dict()\n",
    "\n",
    "#teleprompter = BootstrapFewShotWithRandomSearch(metric=sentenceSimilarity,num_candidate_programs=20, **config)\n",
    "\n",
    "#teleprompter = BootstrapFewShotWithOptuna(metric=sentenceSimilarity,num_candidate_programs=10, **config)\n",
    "#teleprompter = MIPRO(metric=sentenceSimilarity, **config)\n",
    "\n",
    "teleprompter = LabeledFewShot(metric=sentenceSimilarity, **config)\n",
    "optimized_pred = teleprompter.compile(Pred(), trainset=training_data, max_demos=8)\n",
    "#teleprompter = BootstrapFewShot(metric=validate_answer, **config)\n",
    "#optimized_cot = teleprompter.compile(CoT(), trainset=training_data)\n",
    "#optimized_pred = teleprompter.compile(Pred(), trainset=training_data, max_demos=8)\n",
    "#optimized_pred = teleprompter.compile(Pred(), trainset=training_data, num_trials=50, max_bootstrapped_demos=1, \n",
    "            #                            max_labeled_demos=8,eval_kwargs=config,requires_permission_to_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a0d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "# Set up the evaluator, which can be used multiple times.\n",
    "evaluate = Evaluate(devset=training_data, metric=sentenceSimilarity, num_threads=4, display_progress=True, display_table=0)\n",
    "test = Evaluate(devset=test_data, metric=sentenceSimilarity, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "# Evaluate our `optimized_cot` program.\n",
    "#evaluate(optimized_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unoptimised training performance\")\n",
    "evaluate (Pred())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2989773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"optimised training performance\")\n",
    "evaluate(optimized_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unoptimised test performance\")\n",
    "test (Pred())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74faf9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"optimised test performance\")\n",
    "test (optimized_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimized_cot(question='protected String getTimestamp() {Date date = new Date(System.currentTimeMillis()); DateFormat formatter = DateFormat.getDateTimeInstance(DateFormat.SHORT, DateFormat.SHORT);  String finishTime = formatter.format(date); return finishTime;}')\n",
    "\n",
    "optimized_pred(question='public void actionPerformed(ActionEvent evt) {Object source = evt.getSource(); // --- look and feelif ( source == nativeLF   ) {getNativeUI();return;}else if ( source == metalLF   ) {try {System.out.println(\"Metal look & feel chosen\");UIManager.setLookAndFeel(UIManager.getCrossPlatformLookAndFeelClassName());SwingUtilities.updateComponentTreeUI(this); }catch (Exception exc) {System.out.println(\"Error getting UI\");}return;}// others if (context != null) {if ( source == exit ) exitBtnFn();else if ( source == tile   ) bottomPanel.tile();else if ( source == cascade   ) bottomPanel.cascade(); else if ( source == about   ) { }else if (source == mailInBtn) {new MailInTableUI(bottomPanel,mailInBuffer);} else if (source == mailOutBtn) { new MailOutTableUI(bottomPanel,mailOutBuffer);}else if (source == msgHandlerBtn) { new MsgHandlerTableUI(bottomPanel,msgHandlerBuffer); } }  else { JOptionPane.showMessageDialog(this,\"No associated agent\",\"Error Message\", JOptionPane.OK_OPTION); }')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a28c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_pred.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_pred.prog.signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "# Set up the evaluator, which can be used multiple times.\n",
    "evaluate = Evaluate(devset=training_data, metric=sentenceSimilarity, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "# Evaluate our `optimized_cot` program.\n",
    "evaluate(Pred())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo.inspect_history(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877809f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "left",
   "language": "python",
   "name": "left"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
