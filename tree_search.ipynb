{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a0d226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sntn/opt/anaconda3/envs/left/lib/python3.10/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "from datasets import load_dataset\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e88c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sntn/opt/anaconda3/envs/left/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"code_search_net\", \"java\")\n",
    "\n",
    "system_prompt = \"create documentation from the code in the question using the example answers that are given\"\n",
    "\n",
    "# Set up the LM\n",
    "#turbo = dspy.OllamaLocal(model='', max_tokens=250)\n",
    "#turbo = dspy.OllamaLocal(model='llamca3')\n",
    "#turbo = dspy.OllamaLocal(model='mistral')\n",
    "turbo = dspy.OllamaLocal(model='llama3')\n",
    "#ÃŸturbo = dspy.OllamaLocal(model='codegemma:code',system_prompt=system_prompt)\n",
    "#turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct', max_tokens=250)\n",
    "\n",
    "dspy.settings.configure(lm=turbo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7264b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TreeSearch\n",
    "kcases = 10\n",
    "training_data=[]\n",
    "for x in range(kcases):\n",
    "    k=random.randrange(454450)\n",
    "    case=dspy.Example(question=dataset['train'][k]['func_code_string'], answer=dataset['train'][k]['func_documentation_string']).with_inputs('question')\n",
    "    training_data.append(case)\n",
    "treesearcher=TreeSearch.TreeSearch(model=turbo, pruning_threshold=0.01, pruning_delay=10,max_rounds=30,\n",
    "                                   max_labeled_demos=8, sparsity_demos=0.5, training_set = training_data, breadth = 10 )\n",
    "treesearcher.test_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1562c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make training set \n",
    "kcases = 10\n",
    "training_data=[]\n",
    "for x in range(kcases):\n",
    "    k=random.randrange(454450)\n",
    "    case=dspy.Example(question=dataset['train'][k]['func_code_string'], answer=dataset['train'][k]['func_documentation_string']).with_inputs('question')\n",
    "    training_data.append(case)\n",
    "    \n",
    "#make test set \n",
    "\n",
    "\n",
    "kcases = 10\n",
    "test_data=[]\n",
    "for x in range(kcases):\n",
    "    k=random.randrange(454450)\n",
    "    case=dspy.Example(question=dataset['train'][k]['func_code_string'], answer=dataset['train'][k]['func_documentation_string']).with_inputs('question')\n",
    "    test_data.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d177a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "/Users/sntn/opt/anaconda3/envs/left/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def sentenceSimilarity(example, pred,  trace=None):\n",
    "    example_arr = [example]\n",
    "    pred_arr = [pred]\n",
    "    example_embedding = model.encode(example_arr, convert_to_tensor=True)\n",
    "    prediction_embedding = model.encode(pred_arr, convert_to_tensor=True)\n",
    "    return(util.pytorch_cos_sim(example_embedding, prediction_embedding).item())\n",
    "\n",
    "#model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "#model = SentenceTransformer('stsb-roberta-large')\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "similarity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed015086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[1GDone in 1:01 at 20:43:05/10 0:07min/perc 0.14it/s | 1:01:06 => 1:00\n",
      "\u001b[2K\u001b[1GDone in 0:57 at 20:44:02/10 0:05min/perc 0.18it/s | 0:57:05 => 0:57\n",
      "\u001b[2K\u001b[1GDone in 0:57 at 20:45:00/10 0:06min/perc 0.18it/s | 0:57:06 => 0:57\n",
      "\u001b[2K\u001b[1GDone in 0:58 at 20:46:45/10 0:06min/perc 0.18it/s | 0:58:06 => 0:58\n",
      "\u001b[2K\u001b[1GDone in 0:58 at 20:47:42/10 0:06min/perc 0.18it/s | 0:58:06 => 0:58\n",
      "\u001b[2K\u001b[1GDone in 6:53 at 20:47:56/10 0:14min/perc 0.07it/s | 6:53:28 => 0:4227\n",
      "round 0fitness = 0.338028146462007\n",
      "\u001b[2K\u001b[1GDone in 0:54 at 20:48:50/10 0:05min/perc 0.19it/s | 0:54:05 => 0:5444:04\n",
      "\u001b[2K\u001b[1GDone in 0:17 at 20:49:07/10 0:02min/perc 0.66it/s | 0:17:02 => 0:17\n",
      "\u001b[2K\u001b[1GDone in 0:57 at 20:50:35/10 0:05min/perc 0.19it/s | 0:57:05 => 0:57:27\n",
      "\u001b[2K\u001b[1GDone in 0:50 at 20:51:25/10 0:05min/perc 0.21it/s | 0:50:05 => 0:50\n",
      "\u001b[2K\u001b[1GDone in 0:59 at 20:52:24/10 0:06min/perc 0.18it/s | 0:59:06 => 0:59\n",
      "\u001b[2K\u001b[1GDone in 0:39 at 20:53:03/10 0:04min/perc 0.28it/s | 0:39:04 => 0:39\n",
      "\u001b[2K\u001b[1GDone in 0:58 at 20:54:17/10 0:06min/perc 0.18it/s | 0:58:06 => 0:58\n",
      "\u001b[2K\u001b[1GDone in 6:21 at 20:54:17/10 0:58min/perc 0.02it/s | 6:21\n",
      "round 1fitness = 0.34132699397477234\n",
      "\u001b[2K\u001b[1GDone in 0:57 at 20:55:38/10 0:05min/perc 0.19it/s | 0:57:05 => 0:57:25:30\n",
      "\u001b[2K\u001b[1GDone in 1:01 at 20:56:57/10 0:06min/perc 0.17it/s | 1:01:06 => 1:01\n",
      "\u001b[2K\u001b[1GDone in 1:03 at 21:00:13/10 0:06min/perc 0.16it/s | 1:03:06 => 1:02\n",
      "\u001b[2K\u001b[1GDone in 5:56 at 21:00:13/10 1:03min/perc 0.02it/s | 5:56\n",
      "round 2fitness = 0.34132699397477234\n",
      "\u001b[2K\u001b[1GDone in 0:39 at 21:00:52/10 0:04min/perc 0.27it/s | 0:39:04 => 0:39:10:19\n",
      "\u001b[2K\u001b[1GDone in 0:25 at 21:02:21/10 0:02min/perc 0.46it/s | 0:25:02 => 0:25\n",
      "\u001b[2K\u001b[1GDone in 1:00 at 21:03:21/10 0:06min/perc 0.17it/s | 1:00:06 => 0:59\n",
      "\u001b[2K\u001b[1GDone in 1:35 at 21:05:16/10 0:09min/perc 0.11it/s | 1:35:09 => 1:35\n",
      "\u001b[2K\u001b[1GDone in 0:58 at 21:06:14/10 0:05min/perc 0.19it/s | 0:58:05 => 0:58\n",
      "\u001b[2K\u001b[1GDone in 0:57 at 21:07:11/10 0:05min/perc 0.18it/s | 0:57:06 => 0:57\n",
      "\u001b[2K\u001b[1GDone in 6:58 at 21:07:11/10 0:57min/perc 0.02it/s | 6:58\n",
      "round 3fitness = 0.3546423092484474\n",
      "\u001b[2K\u001b[1GDone in 0:17 at 21:07:58/10 0:01min/perc 0.68it/s | 0:17:01 => 0:17:23:27\n",
      "\u001b[2K\u001b[1GDone in 0:47 at 21:10:27/10 0:05min/perc 0.22it/s | 0:47:04 => 0:47\n",
      "\u001b[2K\u001b[1GDone in 1:33 at 21:12:49/10 0:09min/perc 0.11it/s | 1:33:09 => 1:33\n",
      "\u001b[2K\u001b[1GDone in 0:59 at 21:13:48/10 0:06min/perc 0.18it/s | 0:59:06 => 0:59\n",
      "\u001b[2K\u001b[1GDone in 1:34 at 21:15:21/10 0:09min/perc 0.11it/s | 1:34:09 => 1:34\n",
      "\u001b[2K\u001b[1GDone in 8:11 at 21:15:21/10 1:34min/perc 0.01it/s | 8:11\n",
      "round 4fitness = 0.3546423092484474\n",
      "\u001b[2K\u001b[1GDone in 0:58 at 21:16:19/10 0:06min/perc 0.18it/s | 0:58:06 => 0:585:50:14\n",
      "\u001b[2K\u001b[1GDone in 1:00 at 21:17:19/10 0:06min/perc 0.17it/s | 1:00:06 => 1:00\n",
      "\u001b[2K\u001b[1GDone in 1:31 at 21:18:51/10 0:09min/perc 0.11it/s | 1:31:09 => 1:31\n",
      "\u001b[2K\u001b[1GDone in 0:58 at 21:19:48/10 0:06min/perc 0.18it/s | 0:58:06 => 0:581\n",
      "\u001b[2K\u001b[1GDone in 0:57 at 21:20:46/10 0:05min/perc 0.18it/s | 0:57:05 => 0:579\n",
      "\u001b[2K\u001b[1GDone in 1:32 at 21:22:18/10 0:09min/perc 0.11it/s | 1:32:09 => 1:323\n",
      "\u001b[2K\u001b[1GDone in 0:58 at 21:23:15/10 0:05min/perc 0.18it/s | 0:58:06 => 0:580\n",
      "\u001b[2K\u001b[1GDone in 0:56 at 21:24:11/10 0:05min/perc 0.19it/s | 0:56:05 => 0:563\n",
      "\u001b[2K\u001b[1GDone in 0:42 at 21:24:53/10 0:04min/perc 0.25it/s | 0:42:04 => 0:424\n",
      "\u001b[2K\u001b[1GDone in 9:51 at 21:25:12/10 0:19min/perc 0.05it/s | 9:51:41 => 1:004\n",
      "round 5fitness = 0.3583703203634782\n",
      "\u001b[2K\u001b[1GDone in 1:30 at 21:28:11/10 0:09min/perc 0.11it/s | 1:30:09 => 1:306:27:54\n",
      "\u001b[2K\u001b[1GDone in 0:57 at 21:29:07/10 0:05min/perc 0.19it/s | 0:57:06 => 0:57\n",
      "\u001b[2K\u001b[1GDone in 1:33 at 21:30:41/10 0:09min/perc 0.11it/s | 1:33:09 => 1:34\n",
      "[>...................] 0%% | 6/10 1:33min/perc 0.01it/s | 5:29<4:38 => 10:07"
     ]
    }
   ],
   "source": [
    "import TreeSearch\n",
    "treesearcher=TreeSearch.TreeSearch(model=turbo, pruning_threshold=0.01, pruning_delay=10,max_rounds=50,\n",
    "                                   max_labeled_demos=8, sparsity_demos=0.5, training_set = training_data, breadth = 10 )\n",
    "highest_so_far, highest_fitness=treesearcher.compile(sentenceSimilarity,training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dcbba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"hello\"\n",
    "#turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct', max_tokens=250)\n",
    "turbo = dspy.OllamaLocal(model='llama3')\n",
    "response = turbo.request(prompt)\n",
    "print (response[\"choices\"][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(similarity, labels, cmap = \"YlGnBu\"):\n",
    "  df = pd.DataFrame(similarity)\n",
    "  df.columns = labels\n",
    "  df.index = labels\n",
    "  fig, ax = plt.subplots(figsize=(5,5))\n",
    "  sns.heatmap(df, cmap=cmap)\n",
    "\n",
    "\n",
    "\n",
    "def heatmap(training_data):\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    docs = [nlp(n.answer) for n in training_data]\n",
    "    labels = [training_data.answer[:20] for training_data in training_data]\n",
    "    similarity = []\n",
    "    for i in range(len(docs)):\n",
    "        row = []\n",
    "        for j in range(len(docs)):\n",
    "          row.append(docs[i].similarity(docs[j]))\n",
    "        similarity.append(row)\n",
    "    create_heatmap(similarity,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d047a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(\"question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.prog(question=question)\n",
    "    \n",
    "class Pred(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.Predict(\"question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.prog(question=question)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba2ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7033d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a spacy embedding model to compare the example's answer to the classifiers prediction\n",
    "def validate_answer(example, pred, trace=None):\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    print (pred)\n",
    "    answer_vec=nlp(example.answer)\n",
    "    pred_vec=nlp(pred.answer)\n",
    "    return (answer_vec.similarity(pred_vec))\n",
    "\n",
    "embeddings=[]\n",
    "\n",
    "\n",
    "\n",
    "def sentenceSimilarity(example, pred,  trace=None):\n",
    "    example_arr = [example.answer]\n",
    "    pred_arr = [pred.answer]\n",
    "    example_embedding = model.encode(example_arr, convert_to_tensor=True)\n",
    "    prediction_embedding = model.encode(pred_arr, convert_to_tensor=True)\n",
    "    return(util.pytorch_cos_sim(example_embedding, prediction_embedding).item())\n",
    "\n",
    "#model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "#model = SentenceTransformer('stsb-roberta-large')\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "\n",
    "exp = dspy.Example(question=\"some question\", answer=\"This is an indentical sentence\")\n",
    "prd = dspy.Example(question=\"another question\", answer=\"This is an indentical sentence\")\n",
    "\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "prd = dspy.Example(question=\"another question\", answer=\"This is a different sentence\")\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "prd = dspy.Example(question=\"another question\", answer=\"zookeepers and elephants dance the night away\")\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "prd = dspy.Example(question=\"another question\", answer=\"This is an indenticl sentence\")\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "prd = dspy.Example(question=\"another question\", answer=\"This is an identical phrase\")\n",
    "print(sentenceSimilarity(exp,prd))\n",
    "\n",
    "\n",
    "similarity = []\n",
    "#for i in range(len(sentences)):\n",
    " #   row = []\n",
    "   # for j in range(len(sentences)):\n",
    "   #   row.append(util.pytorch_cos_sim(embeddings[i], embeddings[j]).item())\n",
    "#similarity.append(row)\n",
    "    \n",
    "#create_heatmap(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad811c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch,BootstrapFewShotWithOptuna,MIPRO, LabeledFewShot\n",
    "from dspy.teleprompt.vanilla import LabeledFewShot\n",
    "#model = SentenceTransformer('stsb-roberta-large')\n",
    "#model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "#trainModel()\n",
    "\n",
    "# Set up the optimizer: we want to \"bootstrap\" (i.e., self-generate) 4-shot examples of our CoT program.\n",
    "#config = dict(max_bootstrapped_demos=8, max_labeled_demos=8)\n",
    "config = dict()\n",
    "\n",
    "#teleprompter = BootstrapFewShotWithRandomSearch(metric=sentenceSimilarity,num_candidate_programs=20, **config)\n",
    "\n",
    "#teleprompter = BootstrapFewShotWithOptuna(metric=sentenceSimilarity,num_candidate_programs=10, **config)\n",
    "#teleprompter = MIPRO(metric=sentenceSimilarity, **config)\n",
    "\n",
    "teleprompter = LabeledFewShot(metric=sentenceSimilarity, **config)\n",
    "optimized_pred = teleprompter.compile(Pred(), trainset=training_data, max_demos=8)\n",
    "#teleprompter = BootstrapFewShot(metric=validate_answer, **config)\n",
    "#optimized_cot = teleprompter.compile(CoT(), trainset=training_data)\n",
    "#optimized_pred = teleprompter.compile(Pred(), trainset=training_data, max_demos=8)\n",
    "#optimized_pred = teleprompter.compile(Pred(), trainset=training_data, num_trials=50, max_bootstrapped_demos=1, \n",
    "            #                            max_labeled_demos=8,eval_kwargs=config,requires_permission_to_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a0d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "# Set up the evaluator, which can be used multiple times.\n",
    "evaluate = Evaluate(devset=training_data, metric=sentenceSimilarity, num_threads=4, display_progress=True, display_table=0)\n",
    "test = Evaluate(devset=test_data, metric=sentenceSimilarity, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "# Evaluate our `optimized_cot` program.\n",
    "#evaluate(optimized_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unoptimised training performance\")\n",
    "evaluate (Pred())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2989773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"optimised training performance\")\n",
    "evaluate(optimized_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unoptimised test performance\")\n",
    "test (Pred())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74faf9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"optimised test performance\")\n",
    "test (optimized_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimized_cot(question='protected String getTimestamp() {Date date = new Date(System.currentTimeMillis()); DateFormat formatter = DateFormat.getDateTimeInstance(DateFormat.SHORT, DateFormat.SHORT);  String finishTime = formatter.format(date); return finishTime;}')\n",
    "\n",
    "optimized_pred(question='public void actionPerformed(ActionEvent evt) {Object source = evt.getSource(); // --- look and feelif ( source == nativeLF   ) {getNativeUI();return;}else if ( source == metalLF   ) {try {System.out.println(\"Metal look & feel chosen\");UIManager.setLookAndFeel(UIManager.getCrossPlatformLookAndFeelClassName());SwingUtilities.updateComponentTreeUI(this); }catch (Exception exc) {System.out.println(\"Error getting UI\");}return;}// others if (context != null) {if ( source == exit ) exitBtnFn();else if ( source == tile   ) bottomPanel.tile();else if ( source == cascade   ) bottomPanel.cascade(); else if ( source == about   ) { }else if (source == mailInBtn) {new MailInTableUI(bottomPanel,mailInBuffer);} else if (source == mailOutBtn) { new MailOutTableUI(bottomPanel,mailOutBuffer);}else if (source == msgHandlerBtn) { new MsgHandlerTableUI(bottomPanel,msgHandlerBuffer); } }  else { JOptionPane.showMessageDialog(this,\"No associated agent\",\"Error Message\", JOptionPane.OK_OPTION); }')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a28c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_pred.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_pred.prog.signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "# Set up the evaluator, which can be used multiple times.\n",
    "evaluate = Evaluate(devset=training_data, metric=sentenceSimilarity, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "# Evaluate our `optimized_cot` program.\n",
    "evaluate(Pred())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo.inspect_history(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877809f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "left",
   "language": "python",
   "name": "left"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
